[
  {
    "objectID": "artigos/uranium.html",
    "href": "artigos/uranium.html",
    "title": "Sur la pénétration des rayons de Becquerel non déviables par le champ magnétique",
    "section": "",
    "text": "Abstract goes here\nPlus any other information such as supplementary materials.\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "palestras/index.html",
    "href": "palestras/index.html",
    "title": "Talks I’ve given",
    "section": "",
    "text": "Talks I’ve given\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Ordenar por\n       Pré-selecionado\n         \n          Data - Mais velho\n        \n         \n          Data - O mais novo\n        \n         \n          Título\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nData\n\n\nTítulo\n\n\nVenue\n\n\n\n\n\n\n30 jun 1901\n\n\nAdventures with Uranium Rays\n\n\nFrench Academy, Paris\n\n\n\n\n\nNenhum item correspondente\n\n De volta ao topo"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alexsandro Prado",
    "section": "",
    "text": "Uma mente curiosa, sempre em busca de conhecimento. Um entusiasta apaixonado por tecnologia que gosta de explorar o vasto mundo dos dados para extrair insights valiosos.\nProfessor do magistério superior há 12 anos, ministrando disciplinas nas áreas de Contabilidade, Administração e Tecnologia da Informação e Comunicação. Ampla experiência como orientador de trabalhos acadêmicos (trabalhos de conclusão de curso, dissertações).\n\n\nUniversidade Federal da Paraíba (UFPB)\nDoutor em Economia, área de concentração Economia Aplicada\nUniversidade de Brasília (UnB)\nMestre em Ciências Contábeis\nUniversidade Federal da Paraíba (UFPB)\nBacharel em Ciências Contábeis\n\n\n\n\nExperiência sólida em análise e visualização de dados em linguagem R\nETL microdados (RAIS, CAGED, PNADc, BGSD, CVM Cias Abertas)\nSQL (Structured Query Language) para consulta e manipulação de dados\nModelos de sobrevivência, Modelos logit, Estimação em Diff-in-Diff (DID), Propense Score Matching\nDesenvolvimento de dashboards (Flexdashboard)\nDesenvolvimento de blogs e websites em (Posit Quarto)\nMontagem e manutenção de computadores\nInstalação e configuração de sistemas operacionais Linux e Windows\nVirtualização (VirtualBox) e gerenciamento de máquinas virtuais\nConfiguração e administração na Amazon Elastic Compute Cloud (AWS EC2) para computação em nuvem."
  },
  {
    "objectID": "index.html#formação",
    "href": "index.html#formação",
    "title": "Alexsandro Prado",
    "section": "",
    "text": "Universidade Federal da Paraíba (UFPB)\nDoutor em Economia, área de concentração Economia Aplicada\nUniversidade de Brasília (UnB)\nMestre em Ciências Contábeis\nUniversidade Federal da Paraíba (UFPB)\nBacharel em Ciências Contábeis"
  },
  {
    "objectID": "index.html#habilidades",
    "href": "index.html#habilidades",
    "title": "Alexsandro Prado",
    "section": "",
    "text": "Experiência sólida em análise e visualização de dados em linguagem R\nETL microdados (RAIS, CAGED, PNADc, BGSD, CVM Cias Abertas)\nSQL (Structured Query Language) para consulta e manipulação de dados\nModelos de sobrevivência, Modelos logit, Estimação em Diff-in-Diff (DID), Propense Score Matching\nDesenvolvimento de dashboards (Flexdashboard)\nDesenvolvimento de blogs e websites em (Posit Quarto)\nMontagem e manutenção de computadores\nInstalação e configuração de sistemas operacionais Linux e Windows\nVirtualização (VirtualBox) e gerenciamento de máquinas virtuais\nConfiguração e administração na Amazon Elastic Compute Cloud (AWS EC2) para computação em nuvem."
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html",
    "href": "blog/posts/heterocedasticidade.html",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "",
    "text": "A heterocedasticidade e a autocorrelação são problemas comuns na análise de regressão, especialmente em séries temporais e dados econométricos, que podem afetar a validade das inferências e a análise de causalidade.\nHeterocedasticidade refere-se à condição em que a variância dos erros (ou resíduos) de um modelo de regressão não é constante ao longo das observações. Em outras palavras, os erros variam em intensidade dependendo do nível da variável independente. Esse problema pode levar a estimativas ineficientes dos coeficientes da regressão, fazendo com que os testes estatísticos, como o teste t e o teste F, se tornem não confiáveis. Isso significa que as inferências sobre a significância das variáveis podem ser incorretas, resultando em um erro na identificação das relações causais.\nAutocorrelação, por outro lado, ocorre quando os erros do modelo de regressão não são independentes uns dos outros, mas sim correlacionados ao longo do tempo ou das observações. Esse problema é particularmente prevalente em dados de séries temporais. A presença de autocorrelação indica que há padrões não capturados pelo modelo, o que pode levar a subestimação ou superestimação da variabilidade dos coeficientes de regressão. Assim como a heterocedasticidade, a autocorrelação torna os testes estatísticos tradicionais inapropriados, resultando em inferências enganosas e dificultando a análise de causalidade correta."
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html#transformações-de-variáveis",
    "href": "blog/posts/heterocedasticidade.html#transformações-de-variáveis",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "1. Transformações de Variáveis",
    "text": "1. Transformações de Variáveis\nTransformar a variável dependente ou independente pode ajudar a estabilizar a variância dos erros. Transformações comuns incluem:\nLogarítmica: Aplicar o logaritmo na variável dependente pode ser eficaz quando a variância dos erros aumenta com o valor da variável dependente.\n\nmodel_log &lt;- lm(log(salary) ~ experience + education, data = data)\nsummary(model_log)\n\n\nCall:\nlm(formula = log(salary) ~ experience + education, data = data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.071087 -0.021134 -0.000469  0.018983  0.091538 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.906897   0.029442  302.52   &lt;2e-16 ***\nexperience  0.067282   0.001827   36.84   &lt;2e-16 ***\neducation   0.022101   0.001724   12.82   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03314 on 97 degrees of freedom\nMultiple R-squared:  0.9384,    Adjusted R-squared:  0.9371 \nF-statistic:   739 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nRaiz Quadrada: Usar a raiz quadrada da variável dependente pode ser útil em alguns casos.\n\nmodel_sqrt &lt;- lm(sqrt(salary) ~ experience + education, data = data)\nsummary(model_sqrt)\n\n\nCall:\nlm(formula = sqrt(salary) ~ experience + education, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2463 -1.2381 -0.2119  1.1691  5.9950 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  79.9427     1.8098   44.17   &lt;2e-16 ***\nexperience    4.0817     0.1123   36.35   &lt;2e-16 ***\neducation     1.3270     0.1060   12.52   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.037 on 97 degrees of freedom\nMultiple R-squared:  0.9368,    Adjusted R-squared:  0.9354 \nF-statistic: 718.3 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html#modelos-de-regressão-ponderada-wls",
    "href": "blog/posts/heterocedasticidade.html#modelos-de-regressão-ponderada-wls",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "2. Modelos de Regressão Ponderada (WLS)",
    "text": "2. Modelos de Regressão Ponderada (WLS)\nSe a heterocedasticidade é sistemática, ponderar as observações pelo inverso da variância estimada dos erros pode melhorar a eficiência dos estimadores:\n\n# Estimar pesos inversamente proporcionais à variância dos resíduos\nweights &lt;- 1 / lm(abs(residuals(model)) ~ fitted(model))$fitted.values^2\n\n# Ajustar o modelo ponderado\nmodel_wls &lt;- lm(salary ~ experience + education, data = data, weights = weights)\nsummary(model_wls)\n\n\nCall:\nlm(formula = salary ~ experience + education, data = data, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2.6267 -0.8224 -0.1781  0.7972  3.0487 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5057.32     348.80   14.50   &lt;2e-16 ***\nexperience    993.10      18.41   53.94   &lt;2e-16 ***\neducation     301.39      22.46   13.42   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.295 on 97 degrees of freedom\nMultiple R-squared:   0.97, Adjusted R-squared:  0.9694 \nF-statistic:  1569 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html#modelos-generalizados-glm",
    "href": "blog/posts/heterocedasticidade.html#modelos-generalizados-glm",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "3. Modelos Generalizados (GLM)",
    "text": "3. Modelos Generalizados (GLM)\nUsar um modelo de regressão mais flexível, como os modelos lineares generalizados (GLM), pode ser apropriado. Por exemplo, a família de distribuições Gamma pode ser adequada para dados positivos com variância crescente:\n\n# Ajustar um modelo GLM com família Gamma\nmodel_glm &lt;- glm(salary ~ experience + education, data = data, family = Gamma(link = \"log\"))\nsummary(model_glm)\n\n\nCall:\nglm(formula = salary ~ experience + education, family = Gamma(link = \"log\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.907700   0.029539  301.56   &lt;2e-16 ***\nexperience  0.067364   0.001833   36.76   &lt;2e-16 ***\neducation   0.022057   0.001730   12.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.001105443)\n\n    Null deviance: 1.71347  on 99  degrees of freedom\nResidual deviance: 0.10675  on 97  degrees of freedom\nAIC: 1528.4\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html#substituir-variáveis-com-novas-variáveis",
    "href": "blog/posts/heterocedasticidade.html#substituir-variáveis-com-novas-variáveis",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "4. Substituir Variáveis com Novas Variáveis",
    "text": "4. Substituir Variáveis com Novas Variáveis\nÀs vezes, a heterocedasticidade pode ser causada pela omissão de variáveis relevantes. Incluir novas variáveis que capturem a fonte da heterocedasticidade pode ajudar a corrigir o problema.\n\nPasso 1: Preparação dos Dados\nPrimeiro, vamos criar um conjunto de dados fictício que contém algumas variáveis correlacionadas e uma variável dependente.\n\n# Carregar pacotes necessários\nlibrary(ggplot2)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(dplyr)\n\n\nAnexando pacote: 'dplyr'\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    filter, lag\n\n\nOs seguintes objetos são mascarados por 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Criar dados fictícios\nset.seed(123)\nn &lt;- 100\nexperience &lt;- rnorm(n, mean = 5, sd = 2)\neducation &lt;- rnorm(n, mean = 16, sd = 2)\nage &lt;- rnorm(n, mean = 40, sd = 10)\nsalary &lt;- 5000 + 1000 * experience + 300 * education + 150 * age + rnorm(n, mean = 0, sd = 1000)\n\ndata &lt;- data.frame(salary, experience, education, age)\n\n\n\nPasso 2: Ajustar o Modelo de Regressão Inicial\nVamos ajustar um modelo de regressão linear inicial com as variáveis originais.\n\n# Ajustar o modelo de regressão linear\nmodel_initial &lt;- lm(salary ~ experience + education + age, data = data)\n\n# Resumo do modelo inicial\nsummary(model_initial)\n\n\nCall:\nlm(formula = salary ~ experience + education + age, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2491.38  -653.92    56.64   670.33  2532.10 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4979.10    1050.34   4.740 7.39e-06 ***\nexperience    972.27      58.44  16.638  &lt; 2e-16 ***\neducation     323.11      54.73   5.904 5.35e-08 ***\nage           144.26      11.22  12.854  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1052 on 96 degrees of freedom\nMultiple R-squared:  0.8153,    Adjusted R-squared:  0.8095 \nF-statistic: 141.3 on 3 and 96 DF,  p-value: &lt; 2.2e-16\n\n# Teste de Breusch-Pagan para heterocedasticidade\nbp_test_initial &lt;- bptest(model_initial)\nprint(bp_test_initial)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model_initial\nBP = 1.9213, df = 3, p-value = 0.5889\n\n\n\n\nPasso 3: Criar Novas Variáveis\nSuponhamos que a relação entre salary e as variáveis experience, education e age pode ser melhor capturada por variáveis transformadas ou interações entre elas. Vamos criar algumas novas variáveis:\n\n# Criar novas variáveis transformadas e de interação\ndata &lt;- data %&gt;%\n  mutate(experience_sq = experience^2,\n         education_sq = education^2,\n         age_sq = age^2,\n         exp_edu_interaction = experience * education,\n         exp_age_interaction = experience * age,\n         edu_age_interaction = education * age)\n\n\n\nPasso 4: Ajustar o Modelo de Regressão com Novas Variáveis\nAjustamos o modelo de regressão linear novamente, agora incluindo as novas variáveis.\n\n# Ajustar o modelo de regressão linear com novas variáveis\nmodel_new &lt;- lm(salary ~ experience + education + age + \n                  experience_sq + education_sq + age_sq + \n                  exp_edu_interaction + exp_age_interaction + edu_age_interaction, data = data)\n\n# Resumo do modelo novo\nsummary(model_new)\n\n\nCall:\nlm(formula = salary ~ experience + education + age + experience_sq + \n    education_sq + age_sq + exp_edu_interaction + exp_age_interaction + \n    edu_age_interaction, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2447.43  -575.88     6.46   637.16  2491.77 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)         13725.6033  8177.1699   1.679   0.0967 .\nexperience           1188.9324   638.5934   1.862   0.0659 .\neducation            -532.1790   807.9010  -0.659   0.5118  \nage                    19.3482   134.7004   0.144   0.8861  \nexperience_sq         -10.1395    24.4353  -0.415   0.6792  \neducation_sq           14.9166    21.6304   0.690   0.4922  \nage_sq                  0.1987     1.0295   0.193   0.8474  \nexp_edu_interaction     5.2872    37.1765   0.142   0.8872  \nexp_age_interaction    -4.6483     6.1003  -0.762   0.4481  \nedu_age_interaction     8.4608     6.0194   1.406   0.1633  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1063 on 90 degrees of freedom\nMultiple R-squared:  0.823, Adjusted R-squared:  0.8053 \nF-statistic: 46.49 on 9 and 90 DF,  p-value: &lt; 2.2e-16\n\n# Teste de Breusch-Pagan para heterocedasticidade\nbp_test_new &lt;- bptest(model_new)\nprint(bp_test_new)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model_new\nBP = 8.5597, df = 9, p-value = 0.4789"
  },
  {
    "objectID": "blog/posts/heterocedasticidade.html#análise-de-componentes-principais-pca",
    "href": "blog/posts/heterocedasticidade.html#análise-de-componentes-principais-pca",
    "title": "Heterocedasticidade e Autocorrelação: como resolver na prática?",
    "section": "5. Análise de Componentes Principais (PCA)",
    "text": "5. Análise de Componentes Principais (PCA)\nSe as variáveis independentes são altamente correlacionadas, o uso de PCA para reduzir a dimensionalidade pode ajudar a mitigar a heterocedasticidade.\n\nPasso 1: Preparação dos Dados\nVamos criar um conjunto de dados fictício com variáveis correlacionadas:\n\n# Carregar pacotes necessários\nlibrary(ggplot2)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(MASS)\nlibrary(dplyr)\n\n# Criar dados fictícios\nset.seed(123)\nn &lt;- 100\nexperience &lt;- rnorm(n, mean = 5, sd = 2)\neducation &lt;- rnorm(n, mean = 16, sd = 2)\nage &lt;- rnorm(n, mean = 40, sd = 10)\nsalary &lt;- 5000 + 1000 * experience + 300 * education + 150 * age + rnorm(n, mean = 0, sd = experience * 100)\n\ndata &lt;- data.frame(salary, experience, education, age)\n\n\n\nPasso 2: Análise de Componentes Principais (PCA)\nVamos aplicar a PCA às variáveis independentes:\n\n# Padronizar as variáveis independentes\ndata_standardized &lt;- scale(data[, c(\"experience\", \"education\", \"age\")])\n\n# Aplicar PCA\npca &lt;- prcomp(data_standardized, center = TRUE, scale. = TRUE)\n\n# Visualizar a proporção da variância explicada por cada componente\nsummary(pca)\n\nImportance of components:\n                          PC1    PC2    PC3\nStandard deviation     1.0726 0.9900 0.9324\nProportion of Variance 0.3835 0.3267 0.2898\nCumulative Proportion  0.3835 0.7102 1.0000\n\n\n\n\nPasso 3: Seleção de Componentes Principais\nVamos escolher quantos componentes principais (PCs) utilizar com base na proporção da variância explicada:\n\n# Adicionar os componentes principais ao dataframe original\ndata_pca &lt;- data.frame(salary = data$salary, pca$x[, 1:2])  # Escolhendo os 2 primeiros PCs\n\n# Ver os dados com os componentes principais\nhead(data_pca)\n\n    salary        PC1        PC2\n1 22273.57 -1.6807281  1.4217451\n2 22120.70 -1.1845614  0.1235709\n3 22609.83  1.3975878 -0.2722631\n4 21006.18 -0.2159818  0.3810757\n5 19636.21  0.7027710  0.6176000\n6 23767.93  1.5835543 -0.5682535\n\n\n\n\nPasso 4: Ajuste do Modelo de Regressão Linear Usando Componentes Principais\n\n# Ajustar o modelo de regressão linear com os componentes principais\nmodel_pca &lt;- lm(salary ~ PC1 + PC2, data = data_pca)\n\n# Resumo do modelo\nsummary(model_pca)\n\n\nCall:\nlm(formula = salary ~ PC1 + PC2, data = data_pca)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5497.9 -1321.4  -106.2  1311.4  6532.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21069.94     222.54  94.677   &lt;2e-16 ***\nPC1            96.68     208.52   0.464   0.6439    \nPC2          -394.22     225.92  -1.745   0.0842 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2225 on 97 degrees of freedom\nMultiple R-squared:  0.03251,   Adjusted R-squared:  0.01256 \nF-statistic:  1.63 on 2 and 97 DF,  p-value: 0.2013\n\n# Teste de Breusch-Pagan\nbp_test_pca &lt;- bptest(model_pca)\nprint(bp_test_pca)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model_pca\nBP = 0.050589, df = 2, p-value = 0.975\n\n# Ajustar o modelo com erros padrão robustos\nrobust_se_pca &lt;- coeftest(model_pca, vcov = vcovHC(model_pca, type = \"HC1\"))\nprint(robust_se_pca)\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21069.939    222.545 94.6773  &lt; 2e-16 ***\nPC1            96.679    180.262  0.5363  0.59296    \nPC2          -394.219    203.820 -1.9342  0.05601 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nExplicação do Código:\nPreparação dos Dados: Criamos um conjunto de dados fictício com variáveis correlacionadas (experience, education, age) e uma variável dependente (salary).\nPadronização: Padronizamos as variáveis independentes para que todas tenham média 0 e desvio padrão 1.\nAplicação da PCA: Aplicamos PCA às variáveis padronizadas para obter componentes principais não correlacionados.\nSeleção de PCs: Escolhemos os componentes principais que explicam uma proporção significativa da variância (neste exemplo, usamos os dois primeiros PCs).\nAjuste do Modelo: Ajustamos o modelo de regressão linear utilizando os componentes principais selecionados.\nDiagnóstico e Ajuste Robusto: Realizamos o teste de Breusch-Pagan para verificar a presença de heterocedasticidade e ajustamos o modelo com erros padrão robustos, se necessário."
  },
  {
    "objectID": "artigos/index.html",
    "href": "artigos/index.html",
    "title": "Publications",
    "section": "",
    "text": "Publications\n\n\n\n\n\n\n\n   \n     \n     \n       Ordenar por\n       Pré-selecionado\n         \n          Data - Mais velho\n        \n         \n          Data - O mais novo\n        \n         \n          Título\n        \n         \n          Autor\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n    Marie Skłodowska-Curie (1900) Sur la pénétration des rayons de Becquerel non déviables par le champ magnétique. CR Acad Sci, 130, 76-79..\n  \n\n\n\n\nNenhum item correspondente\n\n De volta ao topo"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Alexsandro Prado",
    "section": "",
    "text": "Ordenar por\n       Pré-selecionado\n         \n          Título\n        \n         \n          Data - Mais velho\n        \n         \n          Data - O mais novo\n        \n         \n          Autor\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nHeterocedasticidade e Autocorrelação: como resolver na prática?\n\n\n\neconometria\n\n\n\n\n\n\n\nAlexsandro Prado\n\n\n22 maio 2024\n\n\n\n\n\n\n\n\nNenhum item correspondente\n\n De volta ao topo"
  },
  {
    "objectID": "ensino/index.html",
    "href": "ensino/index.html",
    "title": "Advanced Chemistry",
    "section": "",
    "text": "Advanced Chemistry\nBlah blah\n\n\n\nAdvanced Physics\nDon’t forget to bring your lab coats\n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "palestras/french_academy_1901.html",
    "href": "palestras/french_academy_1901.html",
    "title": "Adventures with Uranium Rays",
    "section": "",
    "text": "Abstract here\n\nSlides\nembed html or pdf slides here\n\n\nVideo\n\n\n\n\n\n  \n  \n\n\n\n\n De volta ao topo"
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Selected R packages I’ve coauthored",
    "section": "",
    "text": "Selected R packages I’ve coauthored\n\n\n\n\n De volta ao topo"
  }
]